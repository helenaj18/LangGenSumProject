Adobe Inc. (NASDAQ:ADBE) MoffettNathanson's Inaugural Technology, Media, and Telecom Conference May 18, 2023 11:00 AM ET Company Participants Scott Belsky - Chief Strategy Officer and EVP, Design & Emerging Products Conference Call Participants Sterling Auty - MoffettNathanson Sterling Auty  We're all set. All right. Thanks, everyone, for joining us. My name is Sterling Auty. I'm a software analyst here at SVB MoffettNathanson. Very happy to have with us, Scott Belsky, who is the Chief Strategy Officer, Head of Design and Emerging Products. And Scott is going to be making his way up to the podium. As he does that, he actually brought a video to share with us to give just some highlights. So why don't we go ahead... [Audio/Video Presentation] Love it. Scott, thanks for joining us. Really appreciate it. Scott Belsky  Yes, of course, because I was like try to like show, not to tell, but there was a quick like myriad of assets representing some of the separate doing across the company. Sterling Auty Well, it's great because a number of the companies that cover its infrastructure software, you can't do anything like that to show a video. So it's great to see some of the products in action. But maybe for those that are in the audience and joining us live on the webcast, you have a new role over the last several months. Maybe just give people a little bit about who you are, your new role within the company and where you're focused. Scott Belsky  Sure. So I came into Adobe through the acquisition of Behance back in 2012. Behance is now a network of around 40 million creatives around the world showcasing their work on their portfolios, came in and was -- it was at Adobe for about three years in my first and helping develop some of the services behind Creative Cloud, Creative Cloud libraries, bringing Creative Cloud to mobile, that sort of thing. Left, because it had been like a 10-year journey. I was an entrepreneur through my three years at Adobe, and then had the opportunity to come back in the Chief Product Officer role, overseeing design engineering and product for the Creative Cloud business. And that was about 5.5 years ago. And the objective there was to really build a set of services that enable people to work across products, bring our products to the cloud. So you can start to use them on mobile and web, that sort of thing; build a 3D and immersive franchise, which is now one of the fastest-growing businesses in the company; and also start to develop new approaches, whether it's through Adobe Express, whether it's through Firefly AI-generated capabilities to fulfill our mission of creativity for all. In January, I took on a new role, Chief of overseeing strategy and M&A, design for the entire company as well as emerging products. And the objective here is really just to focus on some of these fast-changing and quickly emerging products that are really changing the company, making sure that we're aligned across every pixel that we ship across all the products in the company. And also, I think it's a moment where a lot of the different parts of our business are really connecting in some ways. As a lot of you know, we've talked about the clouds kind of coming together and marketers working more closely with Creatives. And we've always found like little ways, little bridges here and there to make these workflows better and much more productive for our customers. But in some ways, AI is like the thread that was always missing in like the stitching of a lot of this stuff. And so now you think about how a marketer works in the Adobe Experience Management platform or personalizing assets for customers and that sort of thing. And now it's very clear how the Creative products and tools and creators in an organization will be a part of that. So those are the types of things I'm focusing on. Question-and-Answer Session Q - Sterling Auty  That's awesome. Before we get too far in, I just want to remind, for those in the audience, if you do want to submit a question, just scan QR code, type in a question, I'll pop up on the iPad, and we'll work it into the discussion. Just going back to the video that you showed, there was a lot of things that were there. What are some of the things that jump out at you that have you excited? Scott Belsky  Yes. I think there -- there are a few -- well, let me answer it this way. If we look out a few years into the future and, in many cases, much sooner than that, what sorts of experience would you expect made possible by Adobe? You should expect that in any of our flagship products, the ability to generate other variations or parts of your work and also explore far more surface area of possibility, as you're trying to solve a problem for a customer or make a movie or make an image or whatever the case may be, do brand development, generative actions will be fully baked into the workflows of these products. And they will just be a native part of creation. You're going to be making something, and there's going to be a Generate button in all kinds of places in different moments, and it's just going to generate various variations. And you can take bits and pieces from different ones, stitching together and make new generations based on that. It's a very kind of empowering for the creative world moment where -- because every creative has always said, if I just had more time, I could explore more possibility and come up with better solutions. And so it's always been a function of time. And so this is technology that sort of turbocharges possibility in that regard. So I think you'll see that in our flagships. I think you'll see far more people in the world gaining creative confidence. I feel like creative confidence kind of peaked for many of us when we were six years old. And it kind of went down from there as people stopped putting our work on their refrigerators. And I think that we're entering an area now where any of us with ideas can kind of come in and prompt and get pieces of video and imagery and whatever else. Of course, when you do that, what is the next thing you want to do? You want to make a change. You want to add text. You want to add a logo. You want to make it on brand. You want to add a little tent. You want to take someone else's style and add it, so you can augment it in some way, shape or form. That's like part of the human desire we all have. I think we're very squarely positioned for that. So people are going to come in with Express and some of our Firefly standalone capabilities. And I hope that we show them wanting to get more serious and take on additional tooling and become better customers of ours. Final thing, I think, you should expect is the whole world of marketing to change. I think it's going to become far more personalized than we can even imagine. I think that e-commerce websites will welcome us by name and have assets that are catered to our own interest and our own -- the stuff that we like and. And that customer data profile is going to be at the core of personalizing these experiences. And the connection with all the source of truth assets is going to be a key part of enabling every digital experience to be hyper-personalized. Sterling Auty  There's a lot to unpack there. First of all, thank you for Photoshop on the iPad. Just that was a big step. So the work that you did there, really appreciate it personally. So I want to hit AI head on. There's definitely two big camps. There's a group of investors that think Adobe is going to be a winner and there's another camp that I think you're going to be negatively disrupted. Obviously, we expect you to believe that you're going to be a winner. But what gives you confidence that Adobe is going to be a winner in generative AI? Scott Belsky  Yes. So I think that there are three core convictions I have deep in my soul, which is why I'm here. Number one is that I think far more people will want to express our ideas and stand out creatively. And I think that making tools like Firefly as well as Adobe Express, as well as making all of our products easier to use, which AI helps us do, and we can get to in a minute, that's going to be great for our business. And I think that we should have 100x more customers at the top of our funnel playing and paying to be able to express themselves creatively and stand out, whether it's at school or on social or with our PowerPoint presentations or whatever it might be. So that's a core conviction. Number two is that Creatives don't ever sit stagnant. If something gets easier for them to do, they don't say, "Oh, great, I'll quit earlier today." They'd use that time to make something better. Just like it's part of how creativity works. Creators are always advancing their segment, just like every athlete is always advancing their sports. The tennis players of today are far better than they were 10 years ago. That's how it's going to roll out and continue to roll out for creative professionals. And we're seeing that because we're testing our features and our products with our customers. And what we're seeing is that they're exploring so many more possibilities at every stage of their journey now and not just enticing them to want to push further and do more and make it better. And so yes, I mean, you could argue, if you have a team of five designers, right? And suddenly, you've freed up 30% of their -- each of their capacity using some of this new technology, does that mean you want to hire now fewer designers? Or does that mean you want to design more things? And I think and better things. And so I'm on the camp. And by the way, the history, for example of engineering. Engineering become more productive every year for decades, yet people keep hiring more engineers because they want to create more products and they want to create better products with the new-found productivity. And so I believe that Creative professionals are continuing to advance their segment, and AI is going to enable them to do that. Sterling Auty  One of the areas that's kind of come up in my investor conversations is around the consumer segment in particular. How does AI impact or benefit that segment of the business? Scott Belsky  Which segment? Sterling Auty  Just the consumer. Scott Belsky  Oh, the consumer user. Sterling Auty  Or prosumer. Scott Belsky  Yes. So -- and we also see this with Express, which I think is very similar. I mean, generative AI is just a source of ingredient assets. And so you could start and find ingredient assets from sorting through templates. You could find them through stock assets. You could find them through prompts now with generative AI. Once you find an asset that you like, you then need to do something with it. And usually, you have to add a text to it. You have to edit it. You have to make it yours. You have to put your product in it, whatever those cases may be. That's why I believe that tools need to be natively integrated into the ingredient and where you're prompting for the ingredients. I think the other thing that people forget, especially on the prosumer and consumer side of things is that we need ideas. We need ideas. That's why people like to browse. People like sort through stock photography. People like to get suggestions for prompt as opposed to have to think of them themselves. And so that's how these tools need to evolve and need to be successful. And so we're obviously squarely positioned with what we're doing with Firefly and Express, but that's our approach to it. Sterling Auty  So let's dive into Firefly. What exactly is Firefly? Scott Belsky  So Firefly is our family of generative AI models that is starting with use cases around text-to-image, text-to-text effect, which is a really cool. You actually saw an example in that video of a word and then you like typed in and you make it like nylon letters or balloons or whatever. And then it instantly creates -- turns those letters into that prompt as well as a vector creation and under development, so many more things like 3D and video and many other -- met the other generative AI capabilities. So the Firefly is our family. Sterling Auty  And is that going to manifest itself as a stand-alone product? Or is that being done inside of like Photoshop? Scott Belsky  Yes. So it will come to market in three ways. It will come to market as both the stand-alone Firefly product and is really baked into Express. And I think that's really where we're monetizing through either people getting more credits to generate more stuff or they're just converting to Express and getting some credits associated with that subscription and then hopefully getting even more credits as they generate more stuff. So that's number one. I think it comes to market through our flagships, and generative capabilities will be baked into every single part of the workflows across these flagships over time. People will be paying for the plan for these flagships, and they'll be getting a lot more value now as a result of some of these AI capabilities, which we hope to capture in the pricing of the plans as well as we hope that they get more generative credits. And if we do a good job of making it so much easier and more exciting to create using generative capabilities, we should be having people add on more credits to their flagship plans. And then the third area is on the enterprise side. And one of the things I'm most excited about, and this goes into that third like sort of belief and conviction I have around personalization, I believe that every brand in the world will have their own proprietary model that is trained on their own assets. And so if you're Nike, for example, what are you going to want your teams to use? You're going to want them to use a commercially viable model that was trained in the right way, which you can talk about Firefly, plus all the assets that Nike has, right, that hopefully are stored in Creative Cloud or in our AEM system. And so we believe that brands will have their own proprietary kind of versions of Firefly that they're using. And that will, of course, be a service they're paying for. Sterling Auty  So there's a number of investors that are brand new to just the world of AI. When you talk about credits and buying more credits, what is this credit idea? What's the monetization model? Scott Belsky  So the monetization model, it's simple in the sense that every customer that is a customer of ours today, as their plans get enhanced with generative AI capabilities, I do believe, again, that they're getting more value, and we should get more value in the traditional business model as it is today as a start, right? Alongside that, there is the idea of every generation you do. So I want to generate 17 versions of this one thing I made for Instagram to be able to fit across every other format of every other social platform. Some of those will require texts to be reimagined. Some of them will require pixels to be added. And for generative AI to guess what would actually fill the frame, there's all kinds of stuff going on behind the scenes to generate those 17 variations that any social media marketer would want. And they used to have to spend days to create. Now they can just generate it. Those are 17 generations, right? And if they have a credits for generations that is -- I don't know, I'm making up a number now, but 1,000 or 2,000, they just start to eat into that as they make more of these requests. Imagine a marketer who is taking a final asset that was delivered to them, and they're sending that asset through our campaign -- Adobe Campaign system to customers around the world. And they want to actually generate 140 versions of this e-mail because they have different geos and different languages and also different images will be more performant based on the data they've captured previously with us. That's -- those are all generative credits that are being leveraged to generate these various assets that they're going to then use for their marketing. And so we need to bake the generation capability into our products. We need to kind of make sure everyone has some so they get the taste of this, and then we want to make sure they just start using it. Sterling Auty  So in essence, it's a consumption-based model? Scott Belsky  It is. Sterling Auty  And then sounds great. You showed the video, but when is this actually going to get in users' hands? Scott Belsky  Yes. So Firefly, we've been rolling out invites into the private beta every single week. And now we have certainly a lot of users. We've announced, there's over 70 million generations that have been done using Firefly by these early customers. We've announced that we've had over 1 million people request access. And also, we've shared that a lot of those million are actually net new Adobe IDs, which is also a trend we see in Express, a lot of net new Adobe IDs coming into the funnel. And imminently, we are going to take off the -- sort of open the floodgates, as we say internally, for Firefly because we have the capacity now ready, and we have the mechanisms to like deliver high-quality service, sort of battle tested. And then once that happens, then it all becomes the go-to-market game. Sterling Auty  So a couple of questions came in from the audience. I want to work in here as well. One is how will Firefly really connect? We talked a little bit with the rest of the Creative Cloud, Creative Suite, but also potentially with Figma, what's the longer-term view of the kind of connectivity? Scott Belsky  Yes. Well, the connection between generative AI and our existing flagships and the marketing tools, I think I just made relatively clear, and I'm happy on some more questions on that, when I look at -- we're in the asset-creation business across all of these different segments. People use our products to make video and images and logos and illustrations and everything else. I'm talking about the Creative Cloud side, of course, of the business. With Figma, people are stitching all these assets together, putting them into an interactive product experience that is then handed off to developers. And of course, around half of Figma users are developers, which are not currently in our ecosystem, and we hope they are soon. But the idea of -- initially, the idea of having all these assets be linked assets is really enticing, and our customers are very excited about the prospect of when they're stitching these -- when they're making those assets and they're handing them off to product designers, they're working with their developers they're working with, having those assets be linked and live. Such that if you update the video or update the image or change the slogan for the Christmas campaign or whatever other things you do in real time, the product designers and developers you work with, they can like update their assets and make sure that these prototypes and the actual interactive product experiences are up to date. So that's kind of one of the major synergy cases we're excited about and aside from getting us into this new market of product design and development. But also, with generative AI, there's all kinds of situations where you're designing a prototype. And you need to generate 50 fake people just to kind of show how a directory would look or you're trying to generate some various versions of a design. So I think the Firefly would be a really exciting integration on the Figma side. Sterling Auty  You talked about Express a couple of times. Help people understand what is Express and where does it fit in the product portfolio? Scott Belsky  Sure. So Express is a mixed media, widely accessible Creative product across web and mobile that really touches the needs of a lot of the people who don't have the skills or the endurance for a learning curve and how to create with some of the Pro products. The part of the insight around Express also is really around organizations, teams in the enterprise. If you have a company these days, you have folks that design the products and design the actual branding and all this stuff, which is hopefully stored in our Creative Cloud library service or in cloud documents that you're using. You also have all these social media marketers and everyone else internally that's making presentations and anyone else that wants to be on brand and have the source of treat brand assets at their fingertips. And so the idea of outfitting all of these social media marketers and other people that you work with in agencies and everything else with the ability to use templates and be able to share it in real time is an important need these days in the world of marketing. One of those moments where I realize this, you remember, everyone remember the Super Bowl where the lights went out for a few seconds? And within 30 seconds, OREO did this campaign, You Can Still Dunk In The Dark. And if you think about what has to happen behind the scenes for a marketing team to think and act in real time, they need to have access to those assets. They can't rely on the design and the branding team. They can't rely on approval processes. They have to have templates they can use, like all this stuff needs to be at their fingertips. And that's kind of this new think and act on real-time world that we're in these days as marketing budgets shift towards social, that we need to outfit brands, companies, teams to work in. So Express is like really squarely focused on some of that on the enterprise side as well. And final thing I would just say is that the content that shows up in social media and increasing other places these days is mixed media. You don't come in to Instagram, sometimes thinking it's going to be an image versus a video versus animation versus text or whatever. It's actually an amalgamation of all those things. So Express is natively a mixed media tool. And the next generation of Express, in my opinion, brings out to an entirely different level, and that's launching imminently. Sterling Auty  Excellent. You also talked about Express, not the separation between Express and Pro. How does AI then, outside of Firefly, manifest itself within the Pro products, within the Creative Cloud Photoshop, et cetera? Scott Belsky  Yes. So yes, of course, Firefly deeply embedded in Express. We talked about that. And with Express, you can also always open up things in the Pro products. That's another feature that's coming, and that's an important part of our funnel and the connective tissue of all these products. But on the flagship side, so what the teams are now doing is with customer empathy, knowing what challenges their customers face and how their customers work every day and what these workflows look like, they know what Firefly is capable of, and they're taking these APIs we have internally and then they're just baking them into all these workflows. And so what you'll see, and I think I showed a little glimpse of it, but we're going to be launching soon a feature in Photoshop called Generative Fill. And it actually literally just anything you select, you can fill it with anything you can imagine. And it makes it completely integrated into the asset you're working with, but it's also a non-destructive asset, which what that means is that you can save it as a layer and you can manipulate that layer without changing the whole thing. Any other prompt based fund tool out there these days is a destructive asset. It just spits it out, and it's -- and then you take it into Photoshop and you have to work with it. Well, what if you didn't have to do that? What if you actually could prompt in Photoshop get something, but it's a non-destructive asset with layers, and you can further edit and make it something that you would use commercially. Sterling Auty  That's been my personal frustration with some of the tools that are out there, is that change process. What about the possibility of a co-pilot type of element within something like Photoshop? Scott Belsky  Yes. So this is another major focus for us right now is -- and this is where Firefly is our foundational models, and those are all built internally and has built on our data sets and everything else. We are also going to be partnering, on the LLM side, to power natural language capabilities across our products. And so you can imagine, I'll make up a name called the Adobe AI Assistant. That is a box on the side of all of our products, across products that greets you, asks you what you're trying to accomplish and functions in three ways. Number one is it certainly trains you and helps you. It's a much better natural language way of navigating. The second thing it does for you is it gives you ideas. So as you're doing something, it might say, "Hey, try this color variation. It performs better or try this font. It might be a better fit." So it's actually suggesting things to you. And then the third thing it's doing is it's actually doing things for you. You can actually use it as a command center. You can say, "Hey, here's an the image. Crop it. Oh, here's video, cut it please out in this audio." And so if you think about what that does to our flagship products, that I'm really excited about, is it boosts success in those products for new customers. Because you can come in and you don't have to now be done with this learning curve of Premiere Pro, which is a Hollywood-grade video editor. You can actually upload a family video. You can use it through the co-pilot capability and then you can see the cursors moving around. And hopefully, at some point, you decide to take control of that cursor. But in that case, you're a successful customer. And one of the things I've been passionate about for almost the last six years in these two roles I've had, is the opportunity for retention being a growth driver. There are some people who just can't figure out some of these products. And every time we make an incremental improvement in retention and success of the customer, that's like a material impact to growth of our business, of our core. And so these technologies can really improve that funnel as well as meet the needs of all the other things we've discussed. Sterling Auty  To me, that's where I think another vector for the TAM expansion. So I'm a Photoshop user, but I don't use it every single day. So whenever my wife says, "Oh, I need this image to do this." Up on the screen is Photoshop on the left and YouTube on the right. Scott Belsky  Right. Sterling Auty  Right? Scott Belsky  Yes. Sterling Auty  Because you're searching YouTube like, how do I blah, blah, blah in Photoshop. Being able to do that, I think, is going to... Scott Belsky  And I think it's a great point. And I think that the next generation will be like, why did they have to do that? Like the idea of YouTube in parallel, like you should never have to do that. So that's why I would say AI is this platform shift because it really changes the nature of how we use all of these products. But for us, it's value expansion in the sense that people are going to get more value out of the tools we're giving them. They're going to be able to explore more possibilities, try more things, convert to more formats and more languages and they're going to be able to pay for that. It's also market expansion because not only is it the net new Adobe ideas you talked about, the net new Adobe ideas we talked about in Firefly Express, but it's also the increased success that customers have in our flagship products. And that's also market expansion, if you think about it because we lose some of those people today. Sterling Auty  Absolutely. One of the other questions that came in kind of along those lines is the marginal cost of the Creative process kind of drives towards zero, how does that really just change the competitive landscape? Meaning that you're not the only ones that are going to want to pursue this path, you guys obviously have a massive head start. But how does it really just change the competitive dynamics out there? Scott Belsky  Well, it's an interesting question, which I don't -- because there's a premise in there I don't fully agree with, which is this notion of the creative process becoming free. Like we're going to continue to charge for our products. And again, like you can always source an asset out there. And then what do you want to do with it is the question. And one thing we haven't really covered is the way that we've approached Firefly was informed by our customers saying to us that they are not willing to use generative AI trained on stuff that was copyrighted and IP-protected. They don't see this commercially viable. And so when I talk to the Omnicoms and Publicis of the world, some of these big brands that are excited about these capabilities, they want -- they're asking me questions like, how exactly how is your training data sourced? I need to attest to my clients that there's absolutely no risk. And if you think about it, it makes sense. In order to have an asset in stock, you need to have model releases and building releases and all that sort of stuff. So there is a desire amongst customers to have commercially viable models, and there's going to always be a creative process around what you do once you get something from those models. And then the final thing I would just say is that creative professionals always push further. So if you give them more time or you make the marginal cost of discovering a solution lower, they will just consider more solutions, and they will just find something better. And so unless we think that digital experience has gotten as good as they'll ever get, and now it's just a matter of reducing the cost to get there, that's one way of looking at the world. I don't look at it that way. I think digital experiences keep getting better. We're going to live in an immersive world. I mean, right now, there's no assets around us. But in a few years, we're all going to have devices, and there's going to be all kinds of content around us. And there's going to be an Adobe brand over my head, and there's going to be all this information that is stimulating and helping me explain what I'm even saying in real time probably, that's content, and that's digital experience getting to another level. And as a company, we believe the future digital experiences will improve. Sterling Auty  So closed captions on steroids. Scott Belsky  I think we are going to be boggling, boggled by what's coming. Sterling Auty  So along the competitive idea and what you're talking about, how big is the Adobe content database? Is there really competitive risks stemming from open source models, the mid journeys, et cetera, being trained on commercially viable content? Scott Belsky  Yes. So I think that -- I think if I were to play this out a little bit, so we have a really strong set of models with Firefly. When we launched Firefly, of course, there were snarky bloggers who went in and typed in Spider-Man doing something in Firefly and Spider-Man doing something in other sort of openly scraped models. And they said, "Wait a second, Firefly doesn't know who Spider-Man is. It's a spider with that looks like a man. What's going on here?" And my response is, that's a feature, not a bug. That's based on what our customers needed in order to feel like they could confidently use us for commercial purposes. But I also was thinking, obviously, in the planning for this, what an opportunity to go to Marvel and have them license the use of their IP for people to use on an end level to have the real Spider-Man. And that's kind of the Spotify model here, right? Is -- and that's like a big debate here, right? Is this like an Napster moment? And is Napster going to be -- does the value of music just go to zero and music's free from now on? Or are there better solutions like Spotify and Apple Music and others? And yes, maybe the recording artists make a little less money than they did in the old CD world, but like that becomes the new kind of mainstream way that, that industry works. And so I happen to believe that we're going to use licensed content in models for all kinds of creative purposes going forward. I believe that the 40-plus million profiles, in Behance, of artists around the world that all have styles that are currently stored and represented as assets in our database, I think those people are going to want to license their style to people in Express, to people in Photoshop and other places in a commercially viable fashion, and that we have the opportunity to be the Spotify, if you will, in between some of that. So that's how -- and by the way, I also think it's easier for the consumer. In our case, the person who's creating something to do it that way as opposed to have some of the risks and sort of the messiness of doing it the Napster way. Sterling Auty  So is that almost like finally getting to -- if I think about like stock photography to get images and the way you monetize. Because I think about Behance files, I also think about DBNR and others that have tried to build that marketplace but it just never seemed to really break through? Scott Belsky  Yes. And I think that the -- it's interesting, like Behance is a marketplace of talent, but we just don't capture. We're not doing the LinkedIn model, and we're also not a headhunter. So we've done these polls where we say, how -- have you been hired through Behance? And how much have you been paid? And we've realized hundreds and hundreds of millions of dollars of transactions go through that platform on a quarterly basis, except it's not -- we're not trying to be in the middle of that. But in this new world where people styles can then be used to train models that can be delivered at the fingertips of people whoever they're creating, I think there's an opportunity for us to explore that. Sterling Auty  How would you kind of characterize what is best-in-class when it comes to these generative AI models for this use case? And where does Adobe fit versus what else is out there? So are you already a leader? Are you catching up? Where does things stand? Scott Belsky  I think we have the best UI for print-based creativity with Firefly in the world right now. And you could argue, one of our biggest competitors is in a Discord channel. So maybe that's a low bar. But we have developed an interface that is really a playground for people to come in and play. We believe that novelty proceeds utility oftentimes, and people need to be able to discover some of these capabilities and play with them before they understand how they can be used in their kind of commercial workflows. And so it's like a great progression here to launch Firefly, see how customers use it. In the same time in parallel, we're building the capabilities into our flagship. So we -- and we have the signal from our customers of how they want to use this stuff. And now it's interesting, though, if you watch people use these prompt-based creative tools, the first thing they do is they're like, let me think of a creative prompt. Like, what am I going to prompt? What do I say? Do I ask for an ad for a tennis racket that won't work? Like I have to be descriptive and I have to -- and so actually realize pretty quickly, they need ideas. And so we're surfacing ideas as well, and that's where I think the styles can come into play to give people ideas of styles for what they might want to get for some creative project they're doing. And then, by the way, as soon as they get something, what do they want to do? They want to edit it. They want to add text. They want to make it theirs, et cetera, et cetera. They can bring it into Express or they can bring it into some of our flagship products. And so that's why we think it's such a powerful new top-of-funnel because it's a very frictionless way to start creating and then to want to take it further. Sterling Auty  So a question came in just following up on earlier one. Maybe you're in a position to answer, and maybe Jonathan can weigh in. But just the idea, have you guys ever recently commented in terms of what portion of the ARR or what portion of the business is consumer/prosumer? I know it's been years ago Adobe did, but is there anything more recent that's been out there?  No. Okay. We'll jump ahead then on it. What is the tech stack that's actually underneath Firefly? Is this -- was this built upon the existing kind of Creative Cloud stack? Scott Belsky  Yes. So the services are... Sterling Auty  Or Sensei. Scott Belsky  Yes. So it is part of the Sensei organization, which is our overall AI effort. And as you all know, I think, like we've been shipping AI features for almost a decade. I mean, neuro filters in Photoshop, content-aware fill in Photoshop and in after effects, liquid mode in the Acrobat business. I mean, we have a pretty robust AI organization. The cool thing about being at Adobe, though, is that the talent we recruit and attract across the marketplace for AI are people who have deep desires to be in, say, imaging or video or 3D. The general purpose AI talent might be attracted by some of the sort of other sort of AI-centric players that are just doing AI. We get the people who like want to go deep in verticals, and that's allowed us to have an advantage in building these imaging models and video models over the years. And so when we started a lot of this work, building our generative models, again, which all were done in-house using hundreds of PhDs and folks who think about this all day every day, we were also able to start to future thing, like how do we make this but in a -- so the asset can be leveraged in these products? How can we make this in a way that can feed the marketing pipeline of the future? So we've been kind of kind of plotting and planting the seeds of a lot of this for years and building the core foundational models. And then in the last few months, it's just become like a whip-up, like everyone is asking all these questions. And internally, we're like, yes, I mean, we've been working on this for quite some time. And the good news is that Firefly, I think, came to the market at the right time, and we're launching it in the right way, like with progressions of people giving us feedback. And now we're pretty ready to open up the floodgates. Sterling Auty  I also want to spend a few minutes kind of on the broader Creative Cloud and specifically a lot of discussion and interest in the acquisition of Figma. Maybe just to kick off for those that are newer to, where does Figma kind of fit within the overall Adobe portfolio? And what's kind of the core technology that they're bringing to the table? Scott Belsky  Sure. Well, Figma is a product design and development platform. And that is a segment we have never really played in at scale, for sure. And it's -- Figma has talked about the fact that almost 50% of their users are developers. We don't really have developers as customers. On the Creative Cloud side, we are in the asset creation business. And so as I was saying earlier and having the idea of connecting the assets and the creation of assets with the process of developing interactive product experiences and shipping them through the use of -- through partnership with developers, that's like -- that's one of the biggest synergies. I would say the second synergy that we're really excited about is Figma's FigJam product, which is a great kind of collaborative tool that we think could very much augment Express and also work with -- for some of our Acrobat customers, et cetera. In terms of the product design and development segment, I mean, clearly, it's big. One of the things that's interesting is that when you deliver these interactive product experiences, the idea of that's -- that ends up -- and there's a lot of synergies with our Digital Experience Cloud as well and how you like to sort of serve these sites and how you optimize and personalize the experiences, that sort of stuff. So there's a number of synergies that we're excited about. Sterling Auty  Is there any part of the Adobe product portfolio kind of overlaps with what they did or what they're doing, I should say? Scott Belsky  No. I mean I think one of the things that I get asked is around the collaborative nature of their products. And I think that what I tried to do -- to clarify for people is there's a difference in the way that developers and product designers and all their stakeholders collaborate, which Figma like serves really well, and the collaboration needs in our other products, which are actually not only distinct from that, but actually pretty well served right now. And if you think about it, Photoshop and Illustrator, now on the web as well. We have share for review across all of our products, which is a way for you to share with any stakeholders. And what we don't actually believe our customers on -- in Photoshop, for example, want is hundreds of people in the same file at once. If you go and you talk to people, in the segment of product design and development, they need that. That's kind of the way that works. However, if you ask a Photoshop customer, do they want three other people in their file at once, let alone 300, they'd like freak out and say like, "What do you mean? I'm making an image. Like that would never want that. And by the way, actually, please don't do that." So we've really focused our collaborative roadmap on all of our creative asset creation products on making sure that it's seamless sharing for feedback and that you can seamlessly share a cloud document. So people can pick up where you left off without relying on a Dropbox or something like that. It's a very different sort of collaboration agenda than what Figma has tackled for product designers and developers. Sterling Auty  Is there anything in the core Figma architecture that comes over that benefits from just -- you mentioned Photoshop and the web, et cetera. We think about Figma and Canva being that -- I don't know if cloud native is even the right discussion of, but what their user environment looks like are there pieces that you will actually be able to benefit from in terms of taking that next step with Creative Cloud? Scott Belsky  Well, I think one of the things I'm excited to explore and we've talked about is bringing some of the Creative Cloud capabilities into the product design and development environment. So in some instances, as you shouldn't have to go to Photoshop from Figma to make and edit to an image. There are certain things we can do in line. We have this incredible library of for letting capabilities in Lightroom that we've packaged up beautifully and can come to the surface in other products. And so it's exciting to bring some of those capabilities to the Figma platform. And I'm sure we have a lot to teach one another as well across all forms of web development. But at the same time, we've actually brought our products to the cloud and added collaborative capabilities that are required across our segments now already on the flagship side. So I'm more focused on the synergies and bringing some of the capabilities to Figma. Sterling Auty  So let's switch over to digital experience as well. That's a newer area for, I think, in terms of your responsibility. I think for over a decade, Adobe has talked about trying to -- and you mentioned this earlier in your prepared -- in your first answers, connecting the content creation tools to data analytics, et cetera, to optimize workflows. Where are we in this journey? Scott Belsky  On the digital experience side? Sterling Auty  Yes. Scott Belsky  Yes. Well, I think the core conviction we talked about a lot these days is that the future of digital experiences will be hyper-personalized. And what that requires is that every company really understands their first-party data, has customer data profiles for all their customers and can do something with it. And so one of the things I think about a lot these days is I'm calling it the digital experience flywheel. But you have all the creative tools and capabilities we've discussed. And then you have all the data that companies have on their customers, their language preferences, their fashion preferences, like any preferences that they have about their customers that they obviously collect and ensure that they can deliver a personalized service, that data is now also driving AI  [technical difficulty] what types of digital experiences you should deliver to your customers? And also with generative AI, you can actually create assets to deliver those experiences, which augments the creative side of the equation. And then you have the delivery of them, which is the DX business. It's the campaigns. It's the websites. It's AM. It's everything else. It's analytics that then feeds more data. And so there's actually a flywheel going on here where the creative side with data and AI feeds the marketing side, which creates more data, which improves the AI, which feeds the creative side and I think it’s amazing… Sterling Auty  Cycle. Scott Belsky  Yes, cycle. And so I think we have to build our products and our roadmap. And so the big bet here is that the future of digital experiences will be personalized. And that's how the next generation of companies will better engage, retain and monetize their own customers, right? And that in order to do that, the data, the AI and the creative, like need to be intrinsically connected with the system. It seems obvious to me, right? And I don't think there's another company that I can think of is in a better position to deliver that. Because we have Adobe Analytics, and we're also sending the campaigns, and we're also the source of truth or brand assets for some of the biggest companies in the world, and they're using our Creative products. And we generative AI now, we can build these finely-tuned models based on their data to better serve their needs. So we have the building blocks, and it's a lot more like sort of clear now how it all comes together. And as AI, as that threat I was referring to earlier, we have to deliver that. Sterling Auty  And it seems like this has been the one area that's been the most fragmented of all the different areas that Adobe, not fragmenting the competitive landscape. There are thousands of companies that do these individual literally niche items. Is this finally the precipice where we can get consolidation in a move to a "platform"? Scott Belsky  Well, a few things from the field. I know that right now, as a lot of companies are facing, how do we increase our efficiency? How do we prepare for this AI world? How do we reduce our cost by having all these vendors all over the place? How do we consolidate? This is helping our conversations right now, because all of our customers want to have a better digital experience they deliver to customers. They want a less fractured stack. They want to make sure that they're future-proofing themselves for the world of AI, and that's like feeding directly into the conversations we're having right now with our customers. Sterling Auty  So a couple more questions in from the audience. I want to make sure we squeeze in. First one is, how do you avoid generative AI just cannibalizing the consumer Prosumer Creative Cloud users with good-enough editing? Stuff that can all happen in AI with no need for a mouse, for example. Scott Belsky  Sure. Listen, I mean, Express is a template-based tool. You can find a template and start with it or you could just use it and not edit it, right? Similarly, generative AI is another source of ingredients at the top of the funnel. If people want to come in and just buy a credit pack and use it and then be done and take it as if it was a stock image or whatever else, that's a new business for us. Essentially, they wanted to be a commercially viable asset that has -- we have kind of credentials that can show that it can be used. If they want to sell it or if they want to put it on and have it being add on Instagram or whatever else, there are signals in the market that the commercial viability of assets is going to matter, just like you can't use a copyrighted image on Google necessarily on Instagram. I mean, I think some of those flavors will follow through. But regardless, it's a source of generated assets. Our job is to make you want to do something with it. And so if you generate an asset and you want to add a title, you want to use your brand kit and make it yours, you want to change something, you want to add a different person in it, you want to make it a more diverse image, whatever the case might be that you have, you're going to want to use tools to do it. And so that's why with the Bard integration, for example, we're going to use the integration of Firefly powering Google's image generation to bring people, once they get that asset, into Express to edit it further. We think that's a tremendous top of funnel opportunity for us, and it's not an exclusive deal. We want to make sure that API access to Firefly is a real business for us, and it's proliferated through any source of generation around, because we're so convinced that people are going to want to do something with this asset. Even if it's just scheduling it to post on a social platform, that Express does that for you. And so it's just a -- it's a widening of the top of funnel. And it's our job to entice people to add text, to edit, to further be creative with it, tap into their own like humanity to become a customer. Sterling Auty  I just think about it this way. It just raised the bar in terms of what you can do. Scott Belsky  Yes. Sterling Auty  This is going to sound simplistic and maybe a little bit silly, but when red-eye reduction became something you could do on your phone, it's not like a killed Photoshop, right? You just focused on what's the next elevation of what you can actually do with the tools. Scott Belsky  I mean, when I talked to a lot of young photographers today, and I'm like, why do you use Lightroom? It's because they want to go further. And it turns out the ubiquity of cameras. And photo-editing capabilities actually makes people want to develop their craft and become better. And so that's a fundamental belief I just have about creativity, is that when you get people tools to do things, they just want to go further. They want to go further. And AI is, no doubt, one of those tailwinds that should make far more people want to be creative, get engaged with these products and certainly take the digital experiences people create to another level. Sterling Auty  Last question is, have the biggest technological jumps in generative AI for text to image -- actually already been made, and now it's just about Adobe executing. So in other words, what inning are we in terms of just the innovation in terms of text to image? Scott Belsky  No. I mean, we're in the early innings. Sterling Auty  That's what I think too. Scott Belsky  And -- we're in the early innings, and there's so many -- I mean there's practical gaps to fill in these models like making hands be perfect, allowing you to prompt with crowds of people. I mean there's so many fascinating puzzles that our teams are cracking right now. They're doing it in such imaginative ways, making sure that you can prompt and get amazing 3-dimensional images that you can then further edit in certain -- in parametric ways just like make that couch bigger and stuff like that. I mean we're in the early, early innings. And it's just -- we're in that novelty phase still. But it's great because more people come in, more people start tinkering. And it's the companies that have the deeply specialized talent, the ability to tune into the customer needs and leverage the resources, to bring that UI to the surface, allow customers to go further and also, in my mind, like can connect it to like the desire to deliver personalized digital experiences, that's like the playbook we're most excited about. Sterling Auty  Love it. With that, Scott, thank you so much for joining us. Scott Belsky  Yes. Thank you. Sterling Auty  Really appreciate it. Scott Belsky  Yes, pleasure.